# Di√°rio de Bordo
## Legendas

|S√≠mbolo|Significado|
|:--|:---|
|:checkered_flag:|Conquista, Milestone
|:exclamation:| Problema|
:sparkles:| Momento Eureka
:coffee:| Pausa

## :blue_square: 28/08:
- Clonei o reposit√≥rio do xv6 e regredi o reposit√≥rio de volta para a vers√£o do commit rev11 pedida no EP.
- Instalei uma m√°quina virtual com Lubuntu para testar a execu√ß√£o do SO. Os pacotes necess√°rios tamb√©m foram instalados.

## :blue_square: 30/08:
- Criei um caminho de compartilhamento de arquivos entre a m√°quina e o host Windows.
- :exclamation: O xv6 consegue ser compilado e executado perfeitamente na m√°quina virtual, mas n√£o quando armazenado na pasta de compartilhamento. Precisamos de outra alternativa...
- :exclamation: A depura√ß√£o remota do GDB funciona com o QEMU, mas a depura√ß√£o do VSCode n√£o funciona com o QEMU.
- Ou seja, precisamos achar outra maneira de compilar e de depurar o xv6 dentro do Window.

## :blue_square: 31/08:
- Instalei o WSL2 para executar um cliente leve com Ubuntu e depurar o xv6 diretamente no Windows.
- :exclamation: Por alguma raz√£o, a compila√ß√£o no WSL2 gera um execut√°vel n√£o boot√°vel, apesar de compilar tudo. Mas a compila√ß√£o na m√°quina virtual com Lubuntu funciona?? Existe alguma diferen√ßa entre as duas m√°quinas...

## :blue_square: 01/08:
- :sparkles: A diferen√ßa aparentemente era a vers√£o do Binutils! N√£o s√≥ a vers√£o do GCC importa como a vers√£o do Binutils tamb√©m. O WSL vem por padr√£o com o Ubuntu 22.04 LTS, e o Binutils 2.38. A m√°quina do Lubuntu executa a vers√£o 24.0.4 LTS, com o Binutils 2.42. Ap√≥s atualizar o WSL2 para a vers√£o mais nova do Ubuntu e o Binutils mais recente, a compila√ß√£o e execu√ß√£o funcionam no WSL2!
- Agora precisamos encontrar como depurar o xv6. O gdb do WSL2 j√° vem funcional e consegue interagir apropriadamente com o stub do GDB no QEMU, mas n√£o quero depurar na m√£o, preciso depurar no VSCode.
- Mesmo configurando o VSCode para conectar com o stub remoto em :26000, o QEMU crasha assim que a conex√£o √© feita, suspeito que seja uma arquitetura bin√°ria incompat√≠vel entre o GDB instalado no Windows e o stub do xv6.
- Encontrei uma extens√£o do VS que permite execut√°-lo dentro do WSL2, e executar o GDB instalado dentro do WSL2. Isso elimina a incompatibilidade arquitetural. Dito isso, o QEMU ainda crasha quando me conecto atrav√©s do depurador do VS.
- :coffee: Pausa para o caf√©.

- :sparkles: O QEMU crashava pois, ao iniciar o gdb na pasta do xv6, o xv6 executa um script .gdbinit. Esse script, entre outras coisas, **J√Å** especifica o comando 'target remote :26000'. Ao tentar especificar o comando denovo, o gdb termina o processo anterior. Ou seja, o VSCode iniciava o gdb na pasta, o .gdbinit iniciava uma conex√£o com o stub em :26000, e depois o VS tentava se conectar mais uma vez a :26000, terminando o QEMU. A solu√ß√£o foi apenas reconfigurar launch.json de forma que o VS apenas inicie o gdb na pasta do xv6, sem nenhuma configura√ß√£o adicional.
- A depura√ß√£o finalmente funciona, mas resta ainda testar a funcionalidade dos breakpoints, al√©m de configurar o ambiente de desenvolvimento, para n√£o ter que compilar ou rodar nada diretamente no terminal.
- :checkered_flag: Os breakpoints do kernel e dos programas de usu√°rio funcionam apropriadamente. Estamos prontos para come√ßar.

## :blue_square: 02/08:
- Precisamos agora descobrir quais arquivos est√£o do lado do kernel e quais est√£o do lado do usu√°rio, al√©m de descobrir quais a participa√ß√£o de cada arquivo relevante na chamada do sistema.

Antes de tudo, o cabe√ßalho _**syscall.h**_ √© usado tanto do lado do Kernel como do lado do usu√°rio, e possui defini√ß√µes de constantes para cada tipo de syscall utilizada no sistema. Essa tabela de constantes √© depois consultada para obter o n√∫mero da chamada desejada pelo seu nome.

Do lado do Kernel, temos os seguintes arquivos:
Arquivo|Objetivo
:---|:--
syscall.c|Implementa a tabela de chamadas de sistema que mapeia os n√∫meros para as fun√ß√µes. Os handlers que recebem a chamada diretamente sempre s√£o prefixados com sys_, retornam um tipo int e n√£o recebem argumentos.
sysproc.c|Implementa√ß√£o dos handlers das syscalls relacionadas a manuseamento de processos e mem√≥ria de processos.
sysfile.c|Implementa√ß√£o das syscalls relacionadas ao sistema de arquivos.

Do lado do usu√°rio, s√£o os seguintes arquivos principais:

Arquivo|Funcionalidade
:---|:---
user.h|Prot√≥tipos das fun√ß√µes principais do ambiente de usu√°rio. Inclui tanto os prot√≥tipos das syscalls como algumas chamadas da pseudo-biblioteca C.
usys.S|Implementa√ß√£o em Assembly das fun√ß√µes syscalls declaradas em user.h. Note que a implementa√ß√£o n√£o processa, organiza ou verifica nenhum par√¢metro. Essas responsabilidades ficam do lado do kernel.
ulib.c|Implementa√ß√£o de algumas func√µes da biblioteca C. Algumas operam apenas em mem√≥ria e outras realizam chamadas de sistema.

:sparkles: Agora, √© poss√≠vel entender todo o roteiro do processo de chamada de uma syscall e como o controle da CPU passa de um c√≥digo para outro. Os passos principais (e que teremos que alterar em algum momento) s√£o os seguintes:
1. O programa de usu√°rio chama alguma fun√ß√£o declarada em _user.h_, ex. ```getpid()```.
2. A implementa√ß√£o de ```getpid()``` est√° em _usys.S_, a fun√ß√£o apenas coloca o n√∫mero da syscall pedida (n√∫meros declarados em _syscall.h_) no registrador EAX e realiza o interrupt 64.
3. Atrav√©s do gate declarado na tabela de vetores e inicializado pelo Kernel no boot, o controle √© transferido para o handler de traps no Kernel.
4. O handler de traps interpreta o n√∫mero da interrup√ß√£o e passa o controle para a fun√ß√£o ```syscall()``` implementada em _syscall.c_. Essa fun√ß√£o procura na tabela de chamadas, valida o n√∫mero da syscall executada, e finalmente, passa o controle para o handler apropriado.
5. Para a chamada de sistema nso exemplo, o handler chamado √© o ```sys_getpid()```, definido em _sysproc.c_. A fun√ß√£o tem uma linha s√≥, que obt√©m a estrutura do processo atual e obt√©m o seu ID num√©rico.
6. O controle retorna do kernel atrav√©s do gate de traps e volta para o ambiente de usu√°rio com o id num√©rico do processo.

A chamada de sistema getpid() √© simples pois n√£o recebe qualquer par√¢metro nem realiza opera√ß√µes muito complexas. Para outras syscalls, grande parte do c√≥digo implementado consiste em processar os par√¢metros que est√£o na pilha.

- :coffee: Momento do caf√©

---

Estamos prontos para implementar a chamada do sistema.
### Lado do Kernel
Vamos come√ßar atribuindo um novo n√∫mero para a chamada na tabela global de chamadas declarada em _syscall.h_, definirei a nova syscall com essa linha:
```c
#define SYS_getreadcount 22
```
Vamos agora criar um stub para o handler da nova syscall e adicion√°-lo na tabela de _syscall.c_.
Nesse arquivo, criei o seguinte prot√≥tipo: 
```c
extern int sys_getreadcount();
```
Como essa nova chamada lida com informa√ß√µes do processo, irei implement√°-la em _sysproc.c_. Temporariamente, para testar a nova syscall, vou faz√™-la retornar um valor simb√≥lico com a seguinte implementa√ß√£o:
```c
int sys_getreadcount() {
  return 1234567;
}
```
O lado do Kernel est√° pronto, precisamos agora adicionar as chamadas do lado do usu√°rio.
### Lado do Usu√°rio
Primeiro, adicionarei mais uma linha em _usys.S_ que define uma fun√ß√£o que ativa o interrupt da syscall.
```
SYSCALL(getreadcount)
```
Agora, em _user.h_, vamos definir o prot√≥tipo da nova chamada de sistema. Adicionei o seguinte prot√≥tipo:
```c
int getreadcount(void);
```
Para testar essas implementa√ß√µes, fiz uma modifica√ß√£o no programa **cat.c**, para testar a impress√£o do n√∫mero teste 1234567.
```c
int n = getreadcount();
printf(1, "this is a number: %d\n", n);
```

:checkered_flag: O teste funcionou! A chamada do sistema funciona sem crashes e imprime o n√∫mero correto.

## :blue_square: 03/09:
Precisamos agora criar um contador global para o valor. Esse contador deve ser uma vari√°vel global no sistema e possivelmente uma vari√°vel vol√°til a depender se o Kernel √© sincronizado entre mais de uma CPU ou n√£o.
- Tudo ficaria mais f√°cil se a chamada de sistema que incrementa o contador e a chamada que l√™ o contador ficassem no mesmo arquivo.
- Dito isso, √© uma boa ideia mover a nossa chamada ```sys_getreadcount()``` de _sysproc.h_ para _sysread.c_.
- Movi a chamda de sistema para o outro arquivo e ela continua funcionando perfeitamente.

O contador n√£o precisa ser uma vari√°vel vis√≠vel externamente, ela pode ficar resguardada apenas nesse arquivo como uma vari√°vel est√°tica. A vari√°vel pode ser declarada assim:
```
static int read_counter = 10;
```
* Declarei o valor inicial como 10 para testar se o kernel realiza a inicializa√ß√£o apropriada das vari√°veis est√°ticas.

Precisamos de um programa de testes para as chamadas. Podemos utilizar o _test_1.c_ disponibilizado no enunciado do EP1. Esse programa teste realiza as duas chamadas de sistema e compara os valores para descobrir se est√£o sendo atualizados apropriadamente.
* Instalei no reposit√≥rio o programa test_1.c.
* Adicionei o teste no Makefile como um programa de usu√°rio, dele deve ser executado pela linha de comando como ```> test_1```.
* Modifiquei o programa para n√£o s√≥ exibir as diferen√ßas das contagens mas para exibir o valor inicial do contador.

:checkered_flag: O valor 10 √© retornado da chamada do sistema corretamente.

---

Agora, precisamos adicionar o contador na chamada de sistema ```read()```, e retornar o valor desse contador na nossa implementa√ß√£o.
- A implementa√ß√£o est√° na linha 70 com esse corpo:
- Implementarei o contador antes da valida√ß√£o dos argumentos. Ou seja, qualquer chamada para read() incrementar√° esse contador. Posso mudar esse comportamento depois se for necess√°rio.
```c
int sys_read(void) {
  struct file *f;
  int n;
  char *p;

  read_counter++;

  if(argfd(0, 0, &f) < 0 || argint(2, &n) < 0 || argptr(1, &p, n) < 0)
    return -1;

  return fileread(f, p, n);
}
```
üèÅ O contador funciona! A mensagem esperada √© exibida pelo teste 1.

---

O pr√≥ximo passo √© adicionar o teste 2 e garantir que ele funcione. O teste 2 usa concorr√™ncia com as chamadas.
* O teste 2 cria dois processos e invoca as chamadas de read() e getreadcount() intercaladamente. 
* Ambos processos acessar√£o o c√≥digo do kernel simultaneamente.
* Dito isso, precisaremos de um jeito de sincronizar os acessos ao contador para evitar condi√ß√µes de corrida.

Apesar da condi√ß√£o de corrida te√≥ricamente existir, n√£o consegui reproduz√≠-la. Testei com v√°rios n√∫meros diferentes de CPUs e o n√∫mero correto √© exibido toda vez. 
* √â interessante ainda sim garantir que a chamada nunca ter√° problemas caso uma corrida ocorra.

Vamos encontrar um jeito de simular uma situa√ß√£o de corrida.
* Podemos ler a vari√°vel, esperar alguns instantes atrav√©s de um spinlock, increment√°-la, e s√≥ ent√£o guard√°-la.
* Para garantir que o compilador n√£o troque a ordem dessas instru√ß√µes e quebre a nossa simula√ß√£o, tornamos a vari√°vel vol√°til atrav√©s do modificador 'volatile'.

As implementa√ß√µes abaixo causam certamente uma condi√ß√£o de corrida.
```c
static volatile int read_counter = 0;

// Aguarda um n√∫mero espec√≠fico de ciclos de CPU sem fazer nada.
static void spin_wait(int cycles) {
  for (int i = 0; i < cycles; i++) {
    // Garante que esse assembly n√£o ser√° removido pelo otimizador.
    asm("nop");
  }
}

int sys_read(void) {
  struct file *f;
  int n;
  char *p;

  volatile int current_value = read_counter;
  spin_wait(10000);
  read_counter = current_value + 1;

  if(argfd(0, 0, &f) < 0 || argint(2, &n) < 0 || argptr(1, &p, n) < 0)
    return -1;

  return fileread(f, p, n);
}
```

A situa√ß√£o de corrida ocorre toda vez com esse c√≥digo, trabalharemos em cima dele por enquanto.

:coffee: Momento da pausa.

---

Descobriremos uma forma de usar locks para evitar a corrida nessa simula√ß√£o. Se a corrida deixar de ocorrer nessa simula√ß√£o extrema, certamente deixar√° de ocorrer no caso real.